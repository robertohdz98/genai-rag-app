{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG app using GPT\n",
    "\n",
    "Based on https://youtu.be/BrsocJb-fAo?si=ecQjtT3cPC9xGvip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Real Madrid won the Champions League in 2014.', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 17, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Which team won Champions League in 2014?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real Madrid won the Champions League in 2014.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Which team won Champions League in 2014?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human:   Answer the question based on the provided context below.\\nIf you cannot find any information related so you cannot answer it, just\\nreply 'I do not know'.\\n\\nContext: Ramos scored in CL final in 2014.\\nQuestion: Who scored in Champions League final 2014?\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"  Answer the question based on the provided context below.\n",
    "If you cannot find any information related so you cannot answer it, just\n",
    "reply 'I do not know'.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Ramos scored in CL final in 2014.\",\n",
    "              question=\"Who scored in Champions League final 2014?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ramos scored in the Champions League final in 2014.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"Ramos scored in CL final in 2014.\",\n",
    "    \"question\": \"Who scored in Champions League final 2014?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining chains\n",
    "\n",
    "(Question + Context) > Prompt > (Query) Model > (Response) Parser >> Answer\n",
    "\n",
    "(>>Answer + Language) Translation Prompt > (Query) Model > (Response) Parser >> Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"Translate the {answer} to {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El último gol de la final de la Liga de Campeones de 2024 fue anotado por Sergio Ramos con un cabezazo en el último minuto.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "input = {\"answer\": chain, \"language\": itemgetter(\"language\")}\n",
    "\n",
    "translation_chain = input | translation_prompt | model | parser\n",
    "\n",
    "translation_chain.invoke({\n",
    "   # For the previous chain that now serves as input\n",
    "    \"context\": \"Sergio Ramos scored in the last minute. It was a header.\",\n",
    "    \"question\": \"How was the last goal of the CL final 2024?\",\n",
    "    # For the translation chain\n",
    "    \"language\": \"Spanish\"\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Testing with own custom context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_context_file = \"cv.txt\"\n",
    "\n",
    "with open(cv_context_file, \"r\") as f:\n",
    "    context = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The highest level of education of Roberto is an Advanced Master in Artificial Intelligence from KU Leuven (Belgium).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"Which is the highest level of education of Roberto?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roberto speaks two languages, Spanish and English.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"How many languages does Roberto speak?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Roberto has had international experience. He worked as an Artificial Intelligence Researcher intern at VITO in Leuven, Belgium, and also completed an Advanced Master in Artificial Intelligence at KU Leuven in Belgium.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"Has Roberto had any international experience?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Roberto's strength in using containerization and orchestration tools like Docker and Kubernetes.\\n2. Roberto's proficiency in working with various MLOps tools such as Miflow, Kubeflow, and MinIO.\\n3. Roberto's skills in using relational and time-series databases like PostgreSQL and InfluxDB.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"Tell me the 3 most strenghts of Roberto in terms of tools.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not know.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"Does Roberto like football?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
